{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag the Tweet!\n",
    "\n",
    "Tagging a Tweet based on its context! Using Recurrent Neural Networks, NGrams.\n",
    "\n",
    "# Problem Statement\n",
    "\n",
    "        Tag the Tweet is an Application built on python, which understands all the tweets of the trending hashtags\n",
    "        and predicts a hashtag for the given tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import re, datetime, pandas as pd\n",
    "import tweepy as tw\n",
    "from sklearn.utils import shuffle\n",
    "#from ResultMiner import TweetMiner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 01\n",
    "\n",
    "We need a lot of data regarding the Tweets! Hence I am using `tweepy` to authenticate my Twitter Keys and use the API to retrieve the required data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_HASHTAGS_COUNT = 3\n",
    "MIN_HASHTAGS_COUNT = 2\n",
    "US_WOE_ID = 23424977\n",
    "INDIA_WOE_ID = 23424848\n",
    "UK_WOE_ID = 23424975\n",
    "TWEET_LIMIT = 125\n",
    "\n",
    "twitter_details = {\n",
    "    'consumer_key'        : \"pNPFulq7iU1AwsH8WKXcM3VhZ\",\n",
    "    'consumer_secret'     : \"k6weUOaZxYSbBBLCBB5DsshL8iUDWIOLY5WlHK555kHRWOinuQ\",\n",
    "    'access_token_key'    : \"782632596-Zx3pED7JikyG7dBx1a6oIqyQh60qeSMUXHAqjfhg\",\n",
    "    'access_token_secret' : \"DoqjnFjyJIqEEsqUVtnyWX2KYyswA9rTCPtJr9GGfyTHL\"\n",
    "}\n",
    "\n",
    "auth = tw.OAuthHandler(twitter_details['consumer_key'], twitter_details['consumer_secret'])\n",
    "auth.set_access_token(twitter_details['access_token_key'], twitter_details['access_token_secret'])\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetMiner():\n",
    "\n",
    "    def __init__(self, api, tweet_limit):\n",
    "        \n",
    "        self.api = api\n",
    "        self.tweet_limit = tweet_limit\n",
    "        \n",
    "        \n",
    "    def retrieve_data(self, tag, WOE_ID, page_limit):\n",
    "        \n",
    "        cleaned_data = []\n",
    "        latest_max_id = False\n",
    "        jk = True\n",
    "        for i in range(page_limit):\n",
    "            tweets = tw.Cursor(self.api.search,\n",
    "                     q=tag+\" -filter:retweets\",\n",
    "                     lang=\"en\",\n",
    "                     max_id = latest_max_id,\n",
    "                     since=2018-1-1).items(self.tweet_limit)\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                if latest_max_id != tweet.id:\n",
    "                    try:\n",
    "                        data = {\n",
    "                            'id' : tweet.id,\n",
    "                            'user_name' : tweet.user.screen_name,\n",
    "                            'tweet_description' : tweet.text,\n",
    "                            'retweet_count' : tweet.retweet_count,\n",
    "                            'created_at' : tweet.created_at,\n",
    "                            'Location_ID' : WOE_ID,\n",
    "                            'hashtag' : tag\n",
    "                        }\n",
    "                    except:\n",
    "                        data = {\n",
    "                            'id' : tweet.id,\n",
    "                            'user_name' : tweet.user.screen_name,\n",
    "                            'tweet_description' : tweet.text,\n",
    "                            'retweet_count' : 0,\n",
    "                            'created_at' : tweet.created_at,\n",
    "                            'Location_ID' : WOE_ID,\n",
    "                            'hashtag' : tag\n",
    "                        }\n",
    "                    latest_max_id = tweet.id\n",
    "                    cleaned_data.append(data)\n",
    "        \n",
    "        return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_miner = TweetMiner(api, TWEET_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trending_hashtags(trends, hashtags):\n",
    "    trends = trends['trends']\n",
    "    trending_hashtags = []\n",
    "    for trend in trends:\n",
    "        print(trend['name'] + str(trend['tweet_volume']))\n",
    "        print(\"_____________\")\n",
    "        if trend['name'][0] == '#' and trend['tweet_volume'] != None and trend['tweet_volume'] >= 2500:\n",
    "            if not trend in hashtags:\n",
    "                trending_hashtags = trend\n",
    "                break\n",
    "    return trending_hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#CollegeInSixWordsNone\n",
      "_____________\n",
      "Julio Jones46329\n",
      "_____________\n",
      "#PanVisibilityDay29840\n",
      "_____________\n",
      "#TwitterIndia34775\n",
      "_____________\n",
      "KillieNone\n",
      "_____________\n",
      "#CorrieNone\n",
      "_____________\n",
      "DundeeNone\n",
      "_____________\n",
      "#BTSxTheOneShow44265\n",
      "_____________\n"
     ]
    }
   ],
   "source": [
    "hashtags = []\n",
    "hashtags.append(get_trending_hashtags(api.trends_place(US_WOE_ID)[0], hashtags))\n",
    "hashtags.append(get_trending_hashtags(api.trends_place(INDIA_WOE_ID)[0], hashtags))\n",
    "hashtags.append(get_trending_hashtags(api.trends_place(UK_WOE_ID)[0], hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Retrievel from Trending HashTags\n",
    "  We are trying to understand three popular hashtags by mining 1500 tweets each..\n",
    "  Below are the pandas dataframes for each of these. Which we later try to merge back\n",
    "  as on dataset X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '#PanVisibilityDay', 'url': 'http://twitter.com/search?q=%23PanVisibilityDay', 'promoted_content': None, 'query': '%23PanVisibilityDay', 'tweet_volume': 29840}\n",
      "_________________________\n",
      "{'name': '#TwitterIndia', 'url': 'http://twitter.com/search?q=%23TwitterIndia', 'promoted_content': None, 'query': '%23TwitterIndia', 'tweet_volume': 34775}\n",
      "_________________________\n",
      "{'name': '#BTSxTheOneShow', 'url': 'http://twitter.com/search?q=%23BTSxTheOneShow', 'promoted_content': None, 'query': '%23BTSxTheOneShow', 'tweet_volume': 44265}\n",
      "_________________________\n",
      "[{'name': '#PanVisibilityDay', 'url': 'http://twitter.com/search?q=%23PanVisibilityDay', 'promoted_content': None, 'query': '%23PanVisibilityDay', 'tweet_volume': 29840}, {'name': '#TwitterIndia', 'url': 'http://twitter.com/search?q=%23TwitterIndia', 'promoted_content': None, 'query': '%23TwitterIndia', 'tweet_volume': 34775}, {'name': '#BTSxTheOneShow', 'url': 'http://twitter.com/search?q=%23BTSxTheOneShow', 'promoted_content': None, 'query': '%23BTSxTheOneShow', 'tweet_volume': 44265}]\n"
     ]
    }
   ],
   "source": [
    "print(hashtags[0])\n",
    "print(\"_________________________\")\n",
    "print(hashtags[1])\n",
    "print(\"_________________________\")\n",
    "print(hashtags[2])\n",
    "print(\"_________________________\")\n",
    "print(hashtags)\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.append(tweet_miner.retrieve_data(hashtags[0]['name'], US_WOE_ID, 20))\n",
    "US_df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_description</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Location_ID</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1396923606773469189</td>\n",
       "      <td>wormyHQ</td>\n",
       "      <td>happy #PanVisibilityDay !!! remember every sin...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:18:36</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1396923591988420609</td>\n",
       "      <td>JordanWoollenVO</td>\n",
       "      <td>Oh is it #PanVisibilityDay ? I'm still trying ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:18:32</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1396923589606191109</td>\n",
       "      <td>JobsSummary</td>\n",
       "      <td>New job Plant Front End Loader Operator -Dotha...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:18:32</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1396923540306337798</td>\n",
       "      <td>soulmatesbts</td>\n",
       "      <td>i’m out here (just annoying everyone on sc, le...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:18:20</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1396923518454018048</td>\n",
       "      <td>rogeliovall123</td>\n",
       "      <td>Happy #PanVisibilityDay</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:18:15</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>1396862489028083713</td>\n",
       "      <td>_0ptical</td>\n",
       "      <td>WOO, HAPPY #PanVisibilityDay !!! PAN ARTISTS/C...</td>\n",
       "      <td>24</td>\n",
       "      <td>2021-05-24 16:15:44</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>1396862433185214464</td>\n",
       "      <td>TEENAGEWEBHEADD</td>\n",
       "      <td>happy #PanVisibilityDay to me and peter maximo...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 16:15:31</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>1396862368303419398</td>\n",
       "      <td>StpCalinMeThicc</td>\n",
       "      <td>happy #PanVisibilityDay 🥳🥳💕💕💕💕💕</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 16:15:15</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>1396862336313479170</td>\n",
       "      <td>SkjeidyBrady</td>\n",
       "      <td>Happy #PanVisibilityDay to any and all celebra...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 16:15:08</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>1396862323302846467</td>\n",
       "      <td>HaleLuminarae</td>\n",
       "      <td>I’m terrible with words and stuff like that bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 16:15:04</td>\n",
       "      <td>23424977</td>\n",
       "      <td>#PanVisibilityDay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2481 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id        user_name  \\\n",
       "0     1396923606773469189          wormyHQ   \n",
       "1     1396923591988420609  JordanWoollenVO   \n",
       "2     1396923589606191109      JobsSummary   \n",
       "3     1396923540306337798     soulmatesbts   \n",
       "4     1396923518454018048   rogeliovall123   \n",
       "...                   ...              ...   \n",
       "2476  1396862489028083713         _0ptical   \n",
       "2477  1396862433185214464  TEENAGEWEBHEADD   \n",
       "2478  1396862368303419398  StpCalinMeThicc   \n",
       "2479  1396862336313479170     SkjeidyBrady   \n",
       "2480  1396862323302846467    HaleLuminarae   \n",
       "\n",
       "                                      tweet_description  retweet_count  \\\n",
       "0     happy #PanVisibilityDay !!! remember every sin...              0   \n",
       "1     Oh is it #PanVisibilityDay ? I'm still trying ...              0   \n",
       "2     New job Plant Front End Loader Operator -Dotha...              0   \n",
       "3     i’m out here (just annoying everyone on sc, le...              0   \n",
       "4                               Happy #PanVisibilityDay              0   \n",
       "...                                                 ...            ...   \n",
       "2476  WOO, HAPPY #PanVisibilityDay !!! PAN ARTISTS/C...             24   \n",
       "2477  happy #PanVisibilityDay to me and peter maximo...              0   \n",
       "2478                    happy #PanVisibilityDay 🥳🥳💕💕💕💕💕              0   \n",
       "2479  Happy #PanVisibilityDay to any and all celebra...              0   \n",
       "2480  I’m terrible with words and stuff like that bu...              0   \n",
       "\n",
       "              created_at  Location_ID            hashtag  \n",
       "0    2021-05-24 20:18:36     23424977  #PanVisibilityDay  \n",
       "1    2021-05-24 20:18:32     23424977  #PanVisibilityDay  \n",
       "2    2021-05-24 20:18:32     23424977  #PanVisibilityDay  \n",
       "3    2021-05-24 20:18:20     23424977  #PanVisibilityDay  \n",
       "4    2021-05-24 20:18:15     23424977  #PanVisibilityDay  \n",
       "...                  ...          ...                ...  \n",
       "2476 2021-05-24 16:15:44     23424977  #PanVisibilityDay  \n",
       "2477 2021-05-24 16:15:31     23424977  #PanVisibilityDay  \n",
       "2478 2021-05-24 16:15:15     23424977  #PanVisibilityDay  \n",
       "2479 2021-05-24 16:15:08     23424977  #PanVisibilityDay  \n",
       "2480 2021-05-24 16:15:04     23424977  #PanVisibilityDay  \n",
       "\n",
       "[2481 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.append(tweet_miner.retrieve_data(hashtags[1]['name'], INDIA_WOE_ID, 20))\n",
    "India_df = pd.DataFrame(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_description</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Location_ID</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1396927080621740033</td>\n",
       "      <td>KritiPandey06</td>\n",
       "      <td>@sakshijoshii chamchas talking against India w...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:32:24</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1396927003022921728</td>\n",
       "      <td>Wild_Monk_</td>\n",
       "      <td>The bird(murderer of democracy) must be caged....</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:32:05</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1396926862828347393</td>\n",
       "      <td>Ramkuma78515142</td>\n",
       "      <td>. . . good to know the priority of the governm...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:31:32</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1396926823636762624</td>\n",
       "      <td>Vikrantkumarrr</td>\n",
       "      <td>#TwitterIndiaRaid #TwitterIndia \\nIn next two ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:31:23</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1396926590781583363</td>\n",
       "      <td>anantjain14</td>\n",
       "      <td>#TwitterIndia stay strong. \\n#TwitterIndiaRaid</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:30:27</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2476</th>\n",
       "      <td>1396867768583028736</td>\n",
       "      <td>NaveenS92216228</td>\n",
       "      <td>*Twitter India office raided by Delhi Police  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 16:36:43</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2477</th>\n",
       "      <td>1396867767752527877</td>\n",
       "      <td>ind_transformer</td>\n",
       "      <td>#twitterindia\\nMr. Trump now. https://t.co/ktU...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 16:36:43</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>1396867767169474564</td>\n",
       "      <td>Sikande15419419</td>\n",
       "      <td>#TwitterIndia\\n\\n@TwitterIndia it for u. Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-24 16:36:42</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>1396867766167035909</td>\n",
       "      <td>Gandipolitics5</td>\n",
       "      <td>Now who did this 😂😂\\n#AmitShah #KanganaRanaut ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 16:36:42</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>1396867735565393920</td>\n",
       "      <td>nirmal_indian</td>\n",
       "      <td>Why is the Delhi Police raiding offices of #Tw...</td>\n",
       "      <td>20</td>\n",
       "      <td>2021-05-24 16:36:35</td>\n",
       "      <td>23424848</td>\n",
       "      <td>#TwitterIndia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2481 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id        user_name  \\\n",
       "0     1396927080621740033    KritiPandey06   \n",
       "1     1396927003022921728       Wild_Monk_   \n",
       "2     1396926862828347393  Ramkuma78515142   \n",
       "3     1396926823636762624   Vikrantkumarrr   \n",
       "4     1396926590781583363      anantjain14   \n",
       "...                   ...              ...   \n",
       "2476  1396867768583028736  NaveenS92216228   \n",
       "2477  1396867767752527877  ind_transformer   \n",
       "2478  1396867767169474564  Sikande15419419   \n",
       "2479  1396867766167035909   Gandipolitics5   \n",
       "2480  1396867735565393920    nirmal_indian   \n",
       "\n",
       "                                      tweet_description  retweet_count  \\\n",
       "0     @sakshijoshii chamchas talking against India w...              0   \n",
       "1     The bird(murderer of democracy) must be caged....              0   \n",
       "2     . . . good to know the priority of the governm...              0   \n",
       "3     #TwitterIndiaRaid #TwitterIndia \\nIn next two ...              0   \n",
       "4        #TwitterIndia stay strong. \\n#TwitterIndiaRaid              0   \n",
       "...                                                 ...            ...   \n",
       "2476  *Twitter India office raided by Delhi Police  ...              0   \n",
       "2477  #twitterindia\\nMr. Trump now. https://t.co/ktU...              0   \n",
       "2478  #TwitterIndia\\n\\n@TwitterIndia it for u. Take ...              1   \n",
       "2479  Now who did this 😂😂\\n#AmitShah #KanganaRanaut ...              0   \n",
       "2480  Why is the Delhi Police raiding offices of #Tw...             20   \n",
       "\n",
       "              created_at  Location_ID        hashtag  \n",
       "0    2021-05-24 20:32:24     23424848  #TwitterIndia  \n",
       "1    2021-05-24 20:32:05     23424848  #TwitterIndia  \n",
       "2    2021-05-24 20:31:32     23424848  #TwitterIndia  \n",
       "3    2021-05-24 20:31:23     23424848  #TwitterIndia  \n",
       "4    2021-05-24 20:30:27     23424848  #TwitterIndia  \n",
       "...                  ...          ...            ...  \n",
       "2476 2021-05-24 16:36:43     23424848  #TwitterIndia  \n",
       "2477 2021-05-24 16:36:43     23424848  #TwitterIndia  \n",
       "2478 2021-05-24 16:36:42     23424848  #TwitterIndia  \n",
       "2479 2021-05-24 16:36:42     23424848  #TwitterIndia  \n",
       "2480 2021-05-24 16:36:35     23424848  #TwitterIndia  \n",
       "\n",
       "[2481 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "India_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.append(tweet_miner.retrieve_data(hashtags[2]['name'], UK_WOE_ID, 20))\n",
    "UK_df = pd.DataFrame(data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_description</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>Location_ID</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1396929775432785925</td>\n",
       "      <td>MariMoraes3</td>\n",
       "      <td>@BBCTheOneShow @BTSPurpleBullet @BBCiPlayer @B...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:43:06</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1396929214063026176</td>\n",
       "      <td>ttinygoo</td>\n",
       "      <td>my mum watched #BTSxTheOneShow interview with ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:40:52</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1396928778891415552</td>\n",
       "      <td>IlovesmusicBTS</td>\n",
       "      <td>#BTSxTheOneShow\\n I'm so happy and grateful BT...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:39:09</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1396928510065664000</td>\n",
       "      <td>BBC_travelogue</td>\n",
       "      <td>@BleacherReport @brgridiron @undisputed Hi, I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:38:05</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1396928254578069504</td>\n",
       "      <td>BBC_travelogue</td>\n",
       "      <td>@barstoolsports Hi, I am a professional #digit...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-24 20:37:04</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>1396760382920871937</td>\n",
       "      <td>FundsForBTS_UK</td>\n",
       "      <td>BTS will be on The One Show TODAY on @BBCOne!\\...</td>\n",
       "      <td>456</td>\n",
       "      <td>2021-05-24 09:30:00</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>1396428993608437760</td>\n",
       "      <td>pengtingseokjin</td>\n",
       "      <td>Tomorrow we got The One Show. Remember to enga...</td>\n",
       "      <td>6</td>\n",
       "      <td>2021-05-23 11:33:11</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>1395894226060288003</td>\n",
       "      <td>BTSRM_UK</td>\n",
       "      <td>So Ronan Keating @ronanofficial our Irish silk...</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-22 00:08:12</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>1395389993372192770</td>\n",
       "      <td>GirlWithLuv24</td>\n",
       "      <td>BTS will be appearing on BBC One's 'The One Sh...</td>\n",
       "      <td>10</td>\n",
       "      <td>2021-05-20 14:44:34</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>1395383455526133761</td>\n",
       "      <td>idolsmash</td>\n",
       "      <td>I can't wait!!! 💜\\n\\n* 19:00 BST = 15:00 BRT/ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-05-20 14:18:35</td>\n",
       "      <td>23424975</td>\n",
       "      <td>#BTSxTheOneShow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2167 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id        user_name  \\\n",
       "0     1396929775432785925      MariMoraes3   \n",
       "1     1396929214063026176         ttinygoo   \n",
       "2     1396928778891415552   IlovesmusicBTS   \n",
       "3     1396928510065664000   BBC_travelogue   \n",
       "4     1396928254578069504   BBC_travelogue   \n",
       "...                   ...              ...   \n",
       "2162  1396760382920871937   FundsForBTS_UK   \n",
       "2163  1396428993608437760  pengtingseokjin   \n",
       "2164  1395894226060288003         BTSRM_UK   \n",
       "2165  1395389993372192770    GirlWithLuv24   \n",
       "2166  1395383455526133761        idolsmash   \n",
       "\n",
       "                                      tweet_description  retweet_count  \\\n",
       "0     @BBCTheOneShow @BTSPurpleBullet @BBCiPlayer @B...              0   \n",
       "1     my mum watched #BTSxTheOneShow interview with ...              0   \n",
       "2     #BTSxTheOneShow\\n I'm so happy and grateful BT...              0   \n",
       "3     @BleacherReport @brgridiron @undisputed Hi, I ...              0   \n",
       "4     @barstoolsports Hi, I am a professional #digit...              0   \n",
       "...                                                 ...            ...   \n",
       "2162  BTS will be on The One Show TODAY on @BBCOne!\\...            456   \n",
       "2163  Tomorrow we got The One Show. Remember to enga...              6   \n",
       "2164  So Ronan Keating @ronanofficial our Irish silk...              1   \n",
       "2165  BTS will be appearing on BBC One's 'The One Sh...             10   \n",
       "2166  I can't wait!!! 💜\\n\\n* 19:00 BST = 15:00 BRT/ ...              0   \n",
       "\n",
       "              created_at  Location_ID          hashtag  \n",
       "0    2021-05-24 20:43:06     23424975  #BTSxTheOneShow  \n",
       "1    2021-05-24 20:40:52     23424975  #BTSxTheOneShow  \n",
       "2    2021-05-24 20:39:09     23424975  #BTSxTheOneShow  \n",
       "3    2021-05-24 20:38:05     23424975  #BTSxTheOneShow  \n",
       "4    2021-05-24 20:37:04     23424975  #BTSxTheOneShow  \n",
       "...                  ...          ...              ...  \n",
       "2162 2021-05-24 09:30:00     23424975  #BTSxTheOneShow  \n",
       "2163 2021-05-23 11:33:11     23424975  #BTSxTheOneShow  \n",
       "2164 2021-05-22 00:08:12     23424975  #BTSxTheOneShow  \n",
       "2165 2021-05-20 14:44:34     23424975  #BTSxTheOneShow  \n",
       "2166 2021-05-20 14:18:35     23424975  #BTSxTheOneShow  \n",
       "\n",
       "[2167 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UK_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngrams\n",
    "\n",
    "Ngrams helps us in understanding intresting things about the corpus.\n",
    "\n",
    "## For example \n",
    "We can know the similarity of each tweet under a specific tag using the Ngrams. \n",
    "For this purpose we shall:\n",
    "\n",
    "1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('panvisibilityday https', 353),\n",
       " ('happy panvisibilityday', 340),\n",
       " ('visibility day', 221),\n",
       " ('pan visibility', 114),\n",
       " ('panvisibilityday pan', 105),\n",
       " ('pan visibility day', 105),\n",
       " ('panvisibilityday fellow', 101),\n",
       " ('panvisibilityday happy', 99),\n",
       " ('pansexual panromantic', 89),\n",
       " ('panvisibilityday pansexual', 82),\n",
       " ('panvisibilitydayhappy panvisibilityday', 81),\n",
       " ('panvisibilityday happy panvisibilityday', 63),\n",
       " ('day panvisibilityday', 61),\n",
       " ('fellow pansexuals', 58),\n",
       " ('pansexual visibility', 58),\n",
       " ('pansexual visibility day', 57),\n",
       " ('panvisibilityday love', 56),\n",
       " ('happy pan', 55),\n",
       " ('panvisibilityday lt', 47),\n",
       " ('panvisibilityday valid', 47)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
    "from collections import Counter\n",
    "\n",
    "vect = tfidf(ngram_range=(2,5), stop_words='english')\n",
    "\n",
    "summaries = \"\".join(US_df['tweet_description'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('twitter india', 329),\n",
       " ('twitterindia https', 327),\n",
       " ('delhi police', 278),\n",
       " ('_क यर_ह', 256),\n",
       " ('india office', 192),\n",
       " ('twitter india office', 188),\n",
       " ('raid twitter', 154),\n",
       " ('special cell', 153),\n",
       " ('raid twitter india', 138),\n",
       " ('police special', 136),\n",
       " ('police special cell', 135),\n",
       " ('twitterindia office', 125),\n",
       " ('raid twitter india office', 121),\n",
       " ('twitterindia twitterindia', 113),\n",
       " ('twitterindia _क', 101),\n",
       " ('twitterindia _क यर_ह', 101),\n",
       " ('twitterindia twitterraid', 86),\n",
       " ('यर_ह twitterindia', 85),\n",
       " ('_क यर_ह twitterindia', 85),\n",
       " ('यर_ह https', 79)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = tfidf(ngram_range=(2,5), stop_words='english')\n",
    "\n",
    "summaries = \"\".join(India_df['tweet_description'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('btsxtheoneshow btsonbbc', 236),\n",
       " ('btsxtheoneshow https', 183),\n",
       " ('bts btsxtheoneshow', 68),\n",
       " ('bts_twt https', 65),\n",
       " ('btsonbbc https', 62),\n",
       " ('btsonbbc bts_twt', 59),\n",
       " ('bts_twt bbctheoneshow', 59),\n",
       " ('make happy', 58),\n",
       " ('btsxtheoneshow btsonbbc https', 58),\n",
       " ('btsxtheoneshow btsonbbc bts_twt', 58),\n",
       " ('happy charge', 55),\n",
       " ('charge batteries', 55),\n",
       " ('btsxtheoneshow bbctheoneshow', 55),\n",
       " ('btsonbbc btsxtheoneshow', 54),\n",
       " ('btsxtheoneshow bts_twt', 54),\n",
       " ('bbctheoneshow bts_twt', 53),\n",
       " ('make happy charge', 52),\n",
       " ('try make', 49),\n",
       " ('bbctheoneshow btsxtheoneshow', 48),\n",
       " ('team try', 46)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = tfidf(ngram_range=(2,5), stop_words='english')\n",
    "\n",
    "summaries = \"\".join(UK_df['tweet_description'])\n",
    "ngrams_summaries = vect.build_analyzer()(summaries)\n",
    "\n",
    "Counter(ngrams_summaries).most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Extraction\n",
    "\n",
    "Now, we need to concat the data we collected from three of these hashtags. We need to prepare our input data and output data to feed them to our model, before doing that we need to:\n",
    "\n",
    "1) Clean the data, by which I mean removing the URLs, emails, punctuations, etc.\n",
    "\n",
    "2) Then we need to build a features vector using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = pd.concat([US_df, India_df, UK_df], axis =0)\n",
    "tweets_data = shuffle(tweets_data)\n",
    "tweets_data.to_csv('hastags_dataframes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use textacy.preprocessing for this module to preprocess the data.\n",
    "\n",
    "## Note: \n",
    "If there is an error installing your textacy saying unable to build wheels for scikit, it has something do with C-compiler in your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from textacy.preprocessing import replace\n",
    "from textacy.preprocessing import remove\n",
    "from textacy.preprocessing.normalize import normalize_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweets(tweet_descriptions):\n",
    "    processed_tweet = []\n",
    "    for tweet in tweet_descriptions:\n",
    "        #BeautifulSoup is the fastest in my experience and hence using it for parsing the HTML\n",
    "        tweet = BeautifulSoup(tweet,'html.parser').get_text() #HTML Parser\n",
    "        \n",
    "        #Replace is also imported from textacy.preprocessing where I wanted to replace certain data with \n",
    "        # generalized terms. Instead of removing them by assigning the parameter replace_with = '', I chose a category\n",
    "        \n",
    "        tweet = replace.replace_emails(tweet,replace_with= 'EMAIL')\n",
    "        tweet = replace.replace_urls(tweet,replace_with= 'URL')\n",
    "        tweet = replace.replace_currency_symbols(tweet,replace_with= 'CURRENCY')\n",
    "        tweet = replace.replace_phone_numbers(tweet,replace_with= 'PHONE')\n",
    "        tweet = replace.replace_emojis(tweet, replace_with='')\n",
    "        #Below are a few methods defined under 'remove' from textacy.preprocessing\n",
    "        #We use it remove Accent characters, punctuations, etc.\n",
    "        tweet = remove.remove_accents(tweet)\n",
    "        tweet = remove.remove_punctuation(tweet)\n",
    "        \n",
    "        tweet = re.sub(' +', ' ', tweet) #Removal of Whitespace; Using regEx to improve the performance\n",
    "        processed_tweet.append(tweet)\n",
    "    return processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#TwitterIndia office is being raided because it called fake what is actually fake. \\n\\nWhy can’t Sambit Patra prove h… https://t.co/kJUuYF6jYq'\n",
      " 'Not gonna lie,when i heard \"what\\'s your favorite food?\" question i was like \"armys?really?are armys really asking o… https://t.co/7xP16m6tnP'\n",
      " 'Tracy beaker omg HI?!?   #BTSxTheOneShow']\n"
     ]
    }
   ],
   "source": [
    "tweet_desc = tweets_data['tweet_description'].values\n",
    "print(tweet_desc[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' TwitterIndia office is being raided because it called fake what is actually fake \\n\\nWhy can t Sambit Patra prove h URL', 'Not gonna lie when i heard what s your favorite food question i was like armys really are armys really asking o URL', 'Tracy beaker omg HI BTSxTheOneShow']\n"
     ]
    }
   ],
   "source": [
    "processed_tweets = preprocess_tweets(tweet_desc)\n",
    "print(processed_tweets[1:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare your Dataset\n",
    "\n",
    "Now that the preprocessing of data is finished, unwanted noises are removed we can prepare our dataset (X, Y)\n",
    "\n",
    "## Input\n",
    "\n",
    "The processed_tweets is our input dataset, however, before feeding to our model there is one last thing to perform that is feature extraction. \n",
    "\n",
    "1) Feature extraction is done using TF-IDF (Term Frequency - Inverse Document Frequency).\n",
    "2) The dimensionality reduction helps us in reducing our processing time without altering the meaning and accuracy.\n",
    "\n",
    "## Output\n",
    "\n",
    "This is a multi-classification problem, hence\n",
    "\n",
    "1) we have three different classes each representing a trending hashtag from three different countries.\n",
    "2) We run the data through a loop and set the y value of that particular tweet to 0 = US, 1 = India, 2 = UK.\n",
    "\n",
    "Note: Before preparing the dataset remember to shuffle the data. So that there are no complications going further.\n",
    "\n",
    "## Train & Test Dataset\n",
    "\n",
    "Divide the data into train and test dataset, inorder to have equal distribution we perform a shuffle before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = []\n",
    "\n",
    "for tag in tweets_data['hashtag'].values:\n",
    "    if tag == hashtags[0]['name']:\n",
    "        Y.append(0)\n",
    "    if tag == hashtags[1]['name']:\n",
    "        Y.append(1)\n",
    "    if tag == hashtags[2]['name']:\n",
    "        Y.append(2)\n",
    "\n",
    "X, Y = shuffle(processed_tweets, Y)\n",
    "X_train_tweet = X[:6000]\n",
    "X_test_tweet =X[6001:]\n",
    "\n",
    "Y_train = Y[:6000]\n",
    "Y_test = Y[6001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tfidf(ngram_range=(2,5), max_features=1500)\n",
    "X_train = tf_idf.fit_transform(X_train_tweet).todense()\n",
    "X_test = tf_idf.fit_transform(X_test_tweet).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 1000 out of 1000 | elapsed: 19.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(multi_class='multinomial'),\n",
       "             param_grid={'C': array([1.00000000e-05, 1.12332403e-05, 1.26185688e-05, 1.41747416e-05,\n",
       "       1.59228279e-05, 1.78864953e-05, 2.00923300e-05, 2.25701972e-05,\n",
       "       2.53536449e-05, 2.84803587e-05, 3.19926714e-05, 3.59381366e-05,\n",
       "       4.03701726e-05, 4.53487851e-05, 5.09413801e-05, 5.72236766e-05,\n",
       "       6.42807312e-...\n",
       "       6.89261210e-02, 7.74263683e-02, 8.69749003e-02, 9.77009957e-02,\n",
       "       1.09749877e-01, 1.23284674e-01, 1.38488637e-01, 1.55567614e-01,\n",
       "       1.74752840e-01, 1.96304065e-01, 2.20513074e-01, 2.47707636e-01,\n",
       "       2.78255940e-01, 3.12571585e-01, 3.51119173e-01, 3.94420606e-01,\n",
       "       4.43062146e-01, 4.97702356e-01, 5.59081018e-01, 6.28029144e-01,\n",
       "       7.05480231e-01, 7.92482898e-01, 8.90215085e-01, 1.00000000e+00]),\n",
       "                         'penalty': ['l2']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "params = {'penalty': ['l2'], 'C':np.logspace(-5,0,100)}\n",
    "\n",
    "gs = GridSearchCV(lr, param_grid=params, cv=10, verbose=1)\n",
    "gs.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.8902150854450392, 'penalty': 'l2'}\n",
      "88.9\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)\n",
    "print(gs.best_score_*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_description</th>\n",
       "      <th>US</th>\n",
       "      <th>IND</th>\n",
       "      <th>UK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>happy PanVisibilityDay &lt;33</td>\n",
       "      <td>0.480622</td>\n",
       "      <td>0.292171</td>\n",
       "      <td>0.227207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HasibaAmin TwitterIndia \\nFirst Take a white ...</td>\n",
       "      <td>0.433518</td>\n",
       "      <td>0.268463</td>\n",
       "      <td>0.298019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ayee it s PanVisibilityDay ️‍ look at me URL</td>\n",
       "      <td>0.246955</td>\n",
       "      <td>0.334831</td>\n",
       "      <td>0.418214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy PanVisibilityDay Everyone and to my part...</td>\n",
       "      <td>0.506907</td>\n",
       "      <td>0.304646</td>\n",
       "      <td>0.188447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thought it d be perfect to use today as an opp...</td>\n",
       "      <td>0.346710</td>\n",
       "      <td>0.522575</td>\n",
       "      <td>0.130715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Reason why TWITTER has some genuinely fine con...</td>\n",
       "      <td>0.185077</td>\n",
       "      <td>0.595926</td>\n",
       "      <td>0.218997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>Ramdev Coronil Twitter all were made an issue ...</td>\n",
       "      <td>0.260587</td>\n",
       "      <td>0.423650</td>\n",
       "      <td>0.315763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>today is PanVisibilityDay and we send so much ...</td>\n",
       "      <td>0.161576</td>\n",
       "      <td>0.311975</td>\n",
       "      <td>0.526449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>Happy PanVisibilityDay to my fellow pan friend...</td>\n",
       "      <td>0.951712</td>\n",
       "      <td>0.031742</td>\n",
       "      <td>0.016547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>I m interested to hear what questions ARMYs as...</td>\n",
       "      <td>0.100111</td>\n",
       "      <td>0.180047</td>\n",
       "      <td>0.719842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Tweet_description        US       IND  \\\n",
       "0                            happy PanVisibilityDay <33  0.480622  0.292171   \n",
       "1      HasibaAmin TwitterIndia \\nFirst Take a white ...  0.433518  0.268463   \n",
       "2          Ayee it s PanVisibilityDay ️‍ look at me URL  0.246955  0.334831   \n",
       "3     Happy PanVisibilityDay Everyone and to my part...  0.506907  0.304646   \n",
       "4     Thought it d be perfect to use today as an opp...  0.346710  0.522575   \n",
       "...                                                 ...       ...       ...   \n",
       "1123  Reason why TWITTER has some genuinely fine con...  0.185077  0.595926   \n",
       "1124  Ramdev Coronil Twitter all were made an issue ...  0.260587  0.423650   \n",
       "1125  today is PanVisibilityDay and we send so much ...  0.161576  0.311975   \n",
       "1126  Happy PanVisibilityDay to my fellow pan friend...  0.951712  0.031742   \n",
       "1127  I m interested to hear what questions ARMYs as...  0.100111  0.180047   \n",
       "\n",
       "            UK  \n",
       "0     0.227207  \n",
       "1     0.298019  \n",
       "2     0.418214  \n",
       "3     0.188447  \n",
       "4     0.130715  \n",
       "...        ...  \n",
       "1123  0.218997  \n",
       "1124  0.315763  \n",
       "1125  0.526449  \n",
       "1126  0.016547  \n",
       "1127  0.719842  \n",
       "\n",
       "[1128 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets = pd.DataFrame(X_test_tweet, columns=[\"Tweet_description\"])\n",
    "predict_tweet = pd.DataFrame(gs.predict_proba(X_test),columns=[\"US\", \"IND\", \"UK\"])\n",
    "pd.merge(test_tweets, predict_tweet, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In this project, we have maintained two training data and test data. Which we do not "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
